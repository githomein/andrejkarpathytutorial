{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Helper function to convert HH:MM:SS to total seconds\n",
    "def hms_to_seconds(time_str):\n",
    "    \"\"\"Convert HH:MM:SS to total seconds.\"\"\"\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"Invalid time format: {time_str}\")\n",
    "    hours, minutes, seconds = map(int, parts)\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "# Define the list of chapters with their timestamps and titles\n",
    "chapters_raw = [\n",
    "    \"00:00:00 intro: Let’s reproduce GPT-2 (124M)\",\n",
    "    \"00:03:39 exploring the GPT-2 (124M) OpenAI checkpoint\",\n",
    "    \"00:13:47 SECTION 1: implementing the GPT-2 nn.Module\",\n",
    "    \"00:28:08 loading the huggingface/GPT-2 parameters\",\n",
    "    \"00:31:00 implementing the forward pass to get logits\",\n",
    "    \"00:33:31 sampling init, prefix tokens, tokenization\",\n",
    "    \"00:37:02 sampling loop\",\n",
    "    \"00:41:47 sample, auto-detect the device\",\n",
    "    \"00:45:50 let’s train: data batches (B,T) → logits (B,T,C)\",\n",
    "    \"00:52:53 cross entropy loss\",\n",
    "    \"00:56:42 optimization loop: overfit a single batch\",\n",
    "    \"01:02:00 data loader lite\",\n",
    "    \"01:06:14 parameter sharing wte and lm_head\",\n",
    "    \"01:13:47 model initialization: std 0.02, residual init\",\n",
    "    \"01:22:18 SECTION 2: Let’s make it fast. GPUs, mixed precision, 1000ms\",\n",
    "    \"01:28:14 Tensor Cores, timing the code, TF32 precision, 333ms\",\n",
    "    \"01:39:38 float16, gradient scalers, bfloat16, 300ms\",\n",
    "    \"01:48:15 torch.compile, Python overhead, kernel fusion, 130ms\",\n",
    "    \"02:00:18 flash attention, 96ms\",\n",
    "    \"02:06:54 nice/ugly numbers. vocab size 50257 → 50304, 93ms\",\n",
    "    \"02:14:55 SECTION 3: hyperpamaters, AdamW, gradient clipping\",\n",
    "    \"02:21:06 learning rate scheduler: warmup + cosine decay\",\n",
    "    \"02:26:21 batch size schedule, weight decay, FusedAdamW, 90ms\",\n",
    "    \"02:34:09 gradient accumulation\",\n",
    "    \"02:46:52 distributed data parallel (DDP)\",\n",
    "    \"03:10:21 datasets used in GPT-2, GPT-3, FineWeb (EDU)\",\n",
    "    \"03:23:10 validation data split, validation loss, sampling revive\",\n",
    "    \"03:28:23 evaluation: HellaSwag, starting the run\",\n",
    "    \"03:43:05 SECTION 4: results in the morning! GPT-2, GPT-3 repro\",\n",
    "    \"03:56:21 shoutout to llm.c, equivalent but faster code in raw C/CUDA\",\n",
    "    \"03:59:39 summary, phew, build-nanogpt github repo\"\n",
    "]\n",
    "\n",
    "# Parse the raw chapters into a list of dictionaries with title and start time in seconds\n",
    "chapters = []\n",
    "for chapter in chapters_raw:\n",
    "    match = re.match(r\"(\\d{2}:\\d{2}:\\d{2})\\s+(.*)\", chapter)\n",
    "    if match:\n",
    "        time_str, title = match.groups()\n",
    "        start_seconds = hms_to_seconds(time_str)\n",
    "        chapters.append({\"title\": title.strip(), \"start\": start_seconds})\n",
    "    else:\n",
    "        print(f\"Invalid chapter format: {chapter}\")\n",
    "\n",
    "# Sort chapters by start time just in case\n",
    "chapters = sorted(chapters, key=lambda x: x['start'])\n",
    "\n",
    "# Extract video ID from the URL\n",
    "video_url = \"https://www.youtube.com/watch?v=l8pRSuU81PU\"\n",
    "video_id_match = re.search(r\"v=([a-zA-Z0-9_-]{11})\", video_url)\n",
    "if video_id_match:\n",
    "    video_id = video_id_match.group(1)\n",
    "else:\n",
    "    raise ValueError(\"Invalid YouTube URL or unable to extract video ID.\")\n",
    "\n",
    "# Fetch the transcript using youtube_transcript_api\n",
    "try:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching transcript: {e}\")\n",
    "    transcript = []\n",
    "\n",
    "# Organize transcript into chapters\n",
    "organized_transcript = {chapter['title']: [] for chapter in chapters}\n",
    "current_chapter_index = 0\n",
    "num_chapters = len(chapters)\n",
    "\n",
    "for entry in transcript:\n",
    "    time = entry['start']\n",
    "    # Move to the correct chapter based on time\n",
    "    while (current_chapter_index + 1 < num_chapters) and (time >= chapters[current_chapter_index + 1]['start']):\n",
    "        current_chapter_index += 1\n",
    "    current_chapter = chapters[current_chapter_index]['title']\n",
    "    organized_transcript[current_chapter].append(entry['text'])\n",
    "\n",
    "# Function to format seconds back to HH:MM:SS\n",
    "def seconds_to_hms(seconds):\n",
    "    \"\"\"Convert total seconds to HH:MM:SS format.\"\"\"\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    secs = seconds % 60\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(secs):02d}\"\n",
    "\n",
    "# Display the organized transcript\n",
    "for chapter in chapters:\n",
    "    title = chapter['title']\n",
    "    start_time = seconds_to_hms(chapter['start'])\n",
    "    print(f\"### {start_time} {title}\\n\")\n",
    "    chapter_text = ' '.join(organized_transcript[title])\n",
    "    print(f\"{chapter_text}\\n\\n\")\n",
    "\n",
    "# Optionally, save the organized transcript to a Markdown file\n",
    "save_to_file = True  # Set to True if you want to save the output\n",
    "if save_to_file:\n",
    "    with open(\"organized_transcript.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for chapter in chapters:\n",
    "            title = chapter['title']\n",
    "            start_time = seconds_to_hms(chapter['start'])\n",
    "            f.write(f\"### {start_time} {title}\\n\\n\")\n",
    "            chapter_text = ' '.join(organized_transcript[title])\n",
    "            f.write(f\"{chapter_text}\\n\\n\")\n",
    "    print(\"Organized transcript has been saved to 'organized_transcript.md'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall the original fpdf\n",
    "!pip uninstall fpdf -y\n",
    "\n",
    "# Install fpdf2\n",
    "!pip install fpdf2 --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping fpdf as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/x2wk71813djf9s5mrhd4_gdm0000gn/T/ipykernel_16252/401390048.py:54: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF has been saved to 'organized_transcript.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Install the required library\n",
    "!pip uninstall fpdf -y  # Uninstall original fpdf if installed\n",
    "!pip install fpdf2 --quiet  # Install fpdf2\n",
    "\n",
    "# Import necessary libraries\n",
    "from fpdf import FPDF\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import traceback\n",
    "\n",
    "# Define a custom PDF class to handle formatting and two-column layout\n",
    "class PDF(FPDF):\n",
    "    def __init__(self, left_margin=15, top_margin=15, right_margin=15, gutter=10):\n",
    "        \"\"\"\n",
    "        Initialize the PDF with custom margins and column settings.\n",
    "\n",
    "        Parameters:\n",
    "        - left_margin (int): Left margin in mm.\n",
    "        - top_margin (int): Top margin in mm.\n",
    "        - right_margin (int): Right margin in mm.\n",
    "        - gutter (int): Space between columns in mm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.left_margin = left_margin\n",
    "        self.top_margin = top_margin\n",
    "        self.right_margin = right_margin\n",
    "        self.gutter = gutter\n",
    "        # Calculate column width based on page width and margins\n",
    "        self.column_width = (self.w - self.left_margin - self.right_margin - self.gutter) / 2\n",
    "        self.set_auto_page_break(auto=True, margin=15)\n",
    "        self.add_page()\n",
    "        self.set_margins(self.left_margin, self.top_margin, self.right_margin)\n",
    "        # Use built-in Helvetica font\n",
    "        self.set_font(\"Helvetica\", size=12)  # Default font for body text\n",
    "\n",
    "    def header(self):\n",
    "        \"\"\"\n",
    "        Draw a vertical line to separate the two columns on each page.\n",
    "        \"\"\"\n",
    "        self.set_draw_color(200, 200, 200)  # Light gray color for the line\n",
    "        x_start = self.left_margin + self.column_width + self.gutter / 2\n",
    "        y_start = self.top_margin\n",
    "        y_end = self.h - self.b_margin\n",
    "        self.line(x_start, y_start, x_start, y_end)\n",
    "\n",
    "    def footer(self):\n",
    "        \"\"\"\n",
    "        Add a footer with the page number at the bottom center of each page.\n",
    "        \"\"\"\n",
    "        self.set_y(-15)  # Position 15 mm from the bottom\n",
    "        self.set_font('Helvetica', 'I', 8)\n",
    "        self.set_text_color(128)  # Gray color for footer text\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        \"\"\"\n",
    "        Format and add a chapter title centered at the top of the page.\n",
    "\n",
    "        Parameters:\n",
    "        - title (str): The chapter title text.\n",
    "        \"\"\"\n",
    "        self.set_font(\"Helvetica\", 'B', 16)  # Bold, 16pt font\n",
    "        self.set_text_color(0, 102, 204)  # Blue color\n",
    "        # Calculate the width available for the title\n",
    "        title_width = self.w - self.left_margin - self.right_margin\n",
    "        # Set Y position slightly below the top margin\n",
    "        self.set_y(self.top_margin + 5)\n",
    "        # Add the chapter title centered\n",
    "        self.multi_cell(title_width, 10, title, align='C')\n",
    "        self.ln(10)  # Add space after the title\n",
    "        self.set_font(\"Helvetica\", size=12)  # Reset to body text font\n",
    "        self.set_text_color(0)  # Reset text color to black\n",
    "\n",
    "    def chapter_body(self, text):\n",
    "        \"\"\"\n",
    "        Format and add body text to the left column.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The body text.\n",
    "        \"\"\"\n",
    "        self.set_font(\"Helvetica\", size=12)  # 12pt Helvetica\n",
    "        # Single-line spacing: line height equals font size\n",
    "        self.multi_cell(self.column_width, 12, text)\n",
    "        # No additional vertical space to ensure single-line spacing\n",
    "\n",
    "    def add_text_left_column(self, text, is_title=False):\n",
    "        \"\"\"\n",
    "        Add text to the left column, formatting it as a title if specified.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The text to add.\n",
    "        - is_title (bool): Whether the text is a chapter title.\n",
    "        \"\"\"\n",
    "        if is_title:\n",
    "            self.chapter_title(text)\n",
    "        else:\n",
    "            self.chapter_body(text)\n",
    "\n",
    "    def add_page_if_needed(self):\n",
    "        \"\"\"\n",
    "        Check if a new page is needed based on the current y-position.\n",
    "        \"\"\"\n",
    "        if self.get_y() > (self.h - self.b_margin - 20):\n",
    "            self.add_page()\n",
    "\n",
    "    def sanitize_text(self, text):\n",
    "        \"\"\"\n",
    "        Sanitize the text by replacing or removing unsupported characters.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The original text.\n",
    "\n",
    "        Returns:\n",
    "        - str: The sanitized text.\n",
    "        \"\"\"\n",
    "        # Normalize the text to decompose combined characters\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        # Encode to ASCII bytes, ignore characters that can't be encoded\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "        return text\n",
    "\n",
    "    def write_content(self, markdown_file):\n",
    "        \"\"\"\n",
    "        Read the markdown file, sanitize its content, and write it to the PDF.\n",
    "        Each new chapter starts on a new page with the title centered at the top.\n",
    "\n",
    "        Parameters:\n",
    "        - markdown_file (str): Path to the markdown file.\n",
    "        \"\"\"\n",
    "        first_chapter = True  # Flag to check if it's the first chapter\n",
    "        with open(markdown_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"###\"):\n",
    "                    # Identify chapter titles (lines starting with ###)\n",
    "                    title = line.lstrip('#').strip()\n",
    "                    title = self.sanitize_text(title)\n",
    "                    if not first_chapter:\n",
    "                        self.add_page()  # Start a new page for new chapter\n",
    "                    else:\n",
    "                        first_chapter = False  # First chapter, no need to add page\n",
    "                    self.add_text_left_column(title, is_title=True)\n",
    "                elif line == \"\":\n",
    "                    # Handle empty lines by adding minimal vertical space\n",
    "                    self.ln(2)\n",
    "                else:\n",
    "                    # Sanitize and add regular body text\n",
    "                    sanitized_text = self.sanitize_text(line)\n",
    "                    self.add_text_left_column(sanitized_text, is_title=False)\n",
    "                self.add_page_if_needed()\n",
    "\n",
    "# Function to convert Markdown to PDF with the specified formatting\n",
    "def markdown_to_pdf(markdown_file, pdf_file):\n",
    "    \"\"\"\n",
    "    Convert a Markdown file to a formatted PDF with two columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - markdown_file (str): Path to the input Markdown file.\n",
    "    - pdf_file (str): Desired path for the output PDF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf = PDF(left_margin=15, top_margin=15, right_margin=15, gutter=10)\n",
    "        pdf.write_content(markdown_file)\n",
    "        pdf.output(pdf_file)\n",
    "        print(f\"PDF has been saved to '{pdf_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF generation: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'organized_transcript.md' with the path to your Markdown file\n",
    "# and 'organized_transcript.pdf' with your desired PDF file name.\n",
    "markdown_file = \"organized_transcript.md\"  # Path to your Markdown file\n",
    "pdf_file = \"organized_transcript.pdf\"      # Desired PDF output file name\n",
    "markdown_to_pdf(markdown_file, pdf_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the pdf into multiple chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping fpdf as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mPDF has been saved to 'output_pdfs/Chapter_1_000000_intro_Let’s_reproduce_GPT-2_(124M).pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_2_000339_exploring_the_GPT-2_(124M)_OpenAI_checkpoint.pdf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/x2wk71813djf9s5mrhd4_gdm0000gn/T/ipykernel_16252/1675132347.py:55: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF has been saved to 'output_pdfs/Chapter_3_001347_SECTION_1_implementing_the_GPT-2_nn.Module.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_4_002808_loading_the_huggingfaceGPT-2_parameters.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_5_003100_implementing_the_forward_pass_to_get_logits.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_6_003331_sampling_init,_prefix_tokens,_tokenization.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_7_003702_sampling_loop.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_8_004147_sample,_auto-detect_the_device.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_9_004550_let’s_train_data_batches_(B,T)_→_logits_(B,T,C).pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_10_005253_cross_entropy_loss.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_11_005642_optimization_loop_overfit_a_single_batch.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_12_010200_data_loader_lite.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_13_010614_parameter_sharing_wte_and_lm_head.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_14_011347_model_initialization_std_0.02,_residual_init.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_15_012218_SECTION_2_Let’s_make_it_fast._GPUs,_mixed_precision,_1000ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_16_012814_Tensor_Cores,_timing_the_code,_TF32_precision,_333ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_17_013938_float16,_gradient_scalers,_bfloat16,_300ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_18_014815_torch.compile,_Python_overhead,_kernel_fusion,_130ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_19_020018_flash_attention,_96ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_20_020654_niceugly_numbers._vocab_size_50257_→_50304,_93ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_21_021455_SECTION_3_hyperpamaters,_AdamW,_gradient_clipping.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_22_022106_learning_rate_scheduler_warmup_+_cosine_decay.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_23_022621_batch_size_schedule,_weight_decay,_FusedAdamW,_90ms.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_24_023409_gradient_accumulation.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_25_024652_distributed_data_parallel_(DDP).pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_26_031021_datasets_used_in_GPT-2,_GPT-3,_FineWeb_(EDU).pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_27_032310_validation_data_split,_validation_loss,_sampling_revive.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_28_032823_evaluation_HellaSwag,_starting_the_run.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_29_034305_SECTION_4_results_in_the_morning!_GPT-2,_GPT-3_repro.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_30_035621_shoutout_to_llm.c,_equivalent_but_faster_code_in_raw_CCUDA.pdf'\n",
      "PDF has been saved to 'output_pdfs/Chapter_31_035939_summary,_phew,_build-nanogpt_github_repo.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Install the required library\n",
    "!pip uninstall fpdf -y  # Uninstall original fpdf if installed\n",
    "!pip install fpdf2 --quiet  # Install fpdf2\n",
    "\n",
    "# Import necessary libraries\n",
    "from fpdf import FPDF\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import traceback\n",
    "\n",
    "# Define a custom PDF class to handle formatting and two-column layout\n",
    "class PDF(FPDF):\n",
    "    def __init__(self, left_margin=15, top_margin=15, right_margin=15, gutter=10):\n",
    "        \"\"\"\n",
    "        Initialize the PDF with custom margins and column settings.\n",
    "\n",
    "        Parameters:\n",
    "        - left_margin (int): Left margin in mm.\n",
    "        - top_margin (int): Top margin in mm.\n",
    "        - right_margin (int): Right margin in mm.\n",
    "        - gutter (int): Space between columns in mm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.left_margin = left_margin\n",
    "        self.top_margin = top_margin\n",
    "        self.right_margin = right_margin\n",
    "        self.gutter = gutter\n",
    "        # Calculate column width based on page width and margins\n",
    "        self.column_width = (self.w - self.left_margin - self.right_margin - self.gutter) / 2\n",
    "        self.set_auto_page_break(auto=True, margin=15)\n",
    "        # Add a new page in the initializer\n",
    "        self.add_page()\n",
    "        self.set_margins(self.left_margin, self.top_margin, self.right_margin)\n",
    "        # Use built-in Helvetica font\n",
    "        self.set_font(\"Helvetica\", size=12)  # Default font for body text\n",
    "\n",
    "    def header(self):\n",
    "        \"\"\"\n",
    "        Draw a vertical line to separate the two columns on each page.\n",
    "        \"\"\"\n",
    "        self.set_draw_color(200, 200, 200)  # Light gray color for the line\n",
    "        x_start = self.left_margin + self.column_width + self.gutter / 2\n",
    "        y_start = self.top_margin\n",
    "        y_end = self.h - self.b_margin\n",
    "        self.line(x_start, y_start, x_start, y_end)\n",
    "\n",
    "    def footer(self):\n",
    "        \"\"\"\n",
    "        Add a footer with the page number at the bottom center of each page.\n",
    "        \"\"\"\n",
    "        self.set_y(-15)  # Position 15 mm from the bottom\n",
    "        self.set_font('Helvetica', 'I', 8)\n",
    "        self.set_text_color(128)  # Gray color for footer text\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        \"\"\"\n",
    "        Format and add a chapter title centered at the top of the page.\n",
    "\n",
    "        Parameters:\n",
    "        - title (str): The chapter title text.\n",
    "        \"\"\"\n",
    "        self.set_font(\"Helvetica\", 'B', 16)  # Bold, 16pt font\n",
    "        self.set_text_color(0, 102, 204)  # Blue color\n",
    "        # Calculate the width available for the title\n",
    "        title_width = self.w - self.left_margin - self.right_margin\n",
    "        # Set Y position slightly below the top margin\n",
    "        self.set_y(self.top_margin + 5)\n",
    "        # Add the chapter title centered\n",
    "        self.multi_cell(title_width, 10, title, align='C')\n",
    "        self.ln(10)  # Add space after the title\n",
    "        self.set_font(\"Helvetica\", size=12)  # Reset to body text font\n",
    "        self.set_text_color(0)  # Reset text color to black\n",
    "\n",
    "    def chapter_body(self, text):\n",
    "        \"\"\"\n",
    "        Format and add body text to the left column.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The body text.\n",
    "        \"\"\"\n",
    "        self.set_font(\"Helvetica\", size=12)  # 12pt Helvetica\n",
    "        # Single-line spacing: line height equals font size\n",
    "        self.multi_cell(self.column_width, 12, text)\n",
    "        # No additional vertical space to ensure single-line spacing\n",
    "\n",
    "    def add_text_left_column(self, text, is_title=False):\n",
    "        \"\"\"\n",
    "        Add text to the left column, formatting it as a title if specified.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The text to add.\n",
    "        - is_title (bool): Whether the text is a chapter title.\n",
    "        \"\"\"\n",
    "        if is_title:\n",
    "            self.chapter_title(text)\n",
    "        else:\n",
    "            self.chapter_body(text)\n",
    "\n",
    "    def add_page_if_needed(self):\n",
    "        \"\"\"\n",
    "        Check if a new page is needed based on the current y-position.\n",
    "        \"\"\"\n",
    "        if self.get_y() > (self.h - self.b_margin - 20):\n",
    "            self.add_page()\n",
    "\n",
    "    def sanitize_text(self, text):\n",
    "        \"\"\"\n",
    "        Sanitize the text by replacing or removing unsupported characters.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The original text.\n",
    "\n",
    "        Returns:\n",
    "        - str: The sanitized text.\n",
    "        \"\"\"\n",
    "        # Normalize the text to decompose combined characters\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        # Encode to ASCII bytes, ignore characters that can't be encoded\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "        return text\n",
    "\n",
    "# Helper function to sanitize filenames\n",
    "def sanitize_filename(title):\n",
    "    \"\"\"\n",
    "    Sanitize the chapter title to create a valid filename.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): The chapter title.\n",
    "\n",
    "    Returns:\n",
    "    - str: A sanitized filename string.\n",
    "    \"\"\"\n",
    "    # Remove or replace characters that are invalid in filenames\n",
    "    sanitized = re.sub(r'[\\\\/*?:\"<>|]', \"\", title)\n",
    "    sanitized = sanitized.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    "    return sanitized\n",
    "\n",
    "# Function to convert Markdown to multiple PDFs, each per chapter\n",
    "def markdown_to_pdfs(markdown_file, output_dir=\"output_pdfs\"):\n",
    "    \"\"\"\n",
    "    Convert a Markdown file to multiple formatted PDFs, each corresponding to a chapter.\n",
    "\n",
    "    Parameters:\n",
    "    - markdown_file (str): Path to the input Markdown file.\n",
    "    - output_dir (str): Directory where the PDF files will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the output directory if it doesn't exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        chapters = []  # List to hold chapters as tuples (title, body)\n",
    "        current_title = None\n",
    "        current_body = []\n",
    "\n",
    "        # Read and parse the markdown file\n",
    "        with open(markdown_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"###\"):\n",
    "                    # If there's an existing chapter, save it\n",
    "                    if current_title is not None:\n",
    "                        chapters.append((current_title, \"\\n\".join(current_body)))\n",
    "                        current_body = []\n",
    "                    # Start a new chapter\n",
    "                    current_title = line.lstrip('#').strip()\n",
    "                elif line == \"\":\n",
    "                    # Handle empty lines by adding minimal vertical space\n",
    "                    current_body.append(\"\")\n",
    "                else:\n",
    "                    # Add regular body text\n",
    "                    current_body.append(line)\n",
    "            # Append the last chapter after finishing the loop\n",
    "            if current_title is not None:\n",
    "                chapters.append((current_title, \"\\n\".join(current_body)))\n",
    "\n",
    "        # Iterate through each chapter and create a separate PDF\n",
    "        for idx, (title, body) in enumerate(chapters, 1):\n",
    "            pdf = PDF(left_margin=15, top_margin=15, right_margin=15, gutter=10)\n",
    "            sanitized_title = pdf.sanitize_text(title)\n",
    "\n",
    "            # Add chapter title and body to the PDF\n",
    "            pdf.add_text_left_column(sanitized_title, is_title=True)\n",
    "\n",
    "            # Split the body into paragraphs and add to PDF\n",
    "            paragraphs = body.split('\\n')\n",
    "            for para in paragraphs:\n",
    "                para = para.strip()\n",
    "                if para == \"\":\n",
    "                    # Add minimal vertical space for empty lines\n",
    "                    pdf.ln(2)\n",
    "                else:\n",
    "                    sanitized_para = pdf.sanitize_text(para)\n",
    "                    pdf.add_text_left_column(sanitized_para, is_title=False)\n",
    "                pdf.add_page_if_needed()\n",
    "\n",
    "            # Define the PDF filename\n",
    "            filename = f\"Chapter_{idx}_{sanitize_filename(title)}.pdf\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "            # Output the PDF\n",
    "            pdf.output(filepath)\n",
    "            print(f\"PDF has been saved to '{filepath}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF generation: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'organized_transcript.md' with the path to your Markdown file\n",
    "# and specify the desired output directory.\n",
    "markdown_file = \"organized_transcript.md\"  # Path to your Markdown file\n",
    "output_directory = \"output_pdfs\"           # Desired output directory for PDFs\n",
    "markdown_to_pdfs(markdown_file, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "def txt_to_pdf(txt_file, pdf_file):\n",
    "    # Create a PDF object\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Set font\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    # Open the text file in read mode\n",
    "    with open(txt_file, 'r') as file:\n",
    "        for line in file:\n",
    "            pdf.cell(200, 10, txt=line, ln=True)\n",
    "\n",
    "    # Output the PDF file\n",
    "    pdf.output(pdf_file)\n",
    "\n",
    "# Example usage:\n",
    "txt_file = r\"/Users/rafatsiddiqui/Downloads/oLabs/oModels/build-nanogpt/Let's reproduce GPT-2 (124M).txt\"  # Replace with your .txt file path\n",
    "pdf_file = \"output.pdf\"  # Desired output PDF file name\n",
    "txt_to_pdf(txt_file, pdf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from pytube import YouTube\n",
    "import os\n",
    "\n",
    "def extract_video_id(url):\n",
    "    \"\"\"\n",
    "    Extract the YouTube video ID from a URL.\n",
    "    \"\"\"\n",
    "    # Regular expression to extract video ID\n",
    "    regex = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(regex, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL. Please provide a valid URL.\")\n",
    "\n",
    "def get_video_title(video_id):\n",
    "    \"\"\"\n",
    "    Get the title of the YouTube video using pytube.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        yt = YouTube(f\"https://www.youtube.com/watch?v=l8pRSuU81PU\")\n",
    "        return yt.title\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching video title: {e}\")\n",
    "        return video_id  # Fallback to video ID if title cannot be fetched\n",
    "\n",
    "def fetch_transcript(video_id):\n",
    "    \"\"\"\n",
    "    Fetch the transcript for the given YouTube video ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        # Prefer English transcript; change 'en' to desired language code if needed\n",
    "        transcript = transcript_list.find_transcript(['en'])\n",
    "        transcript_data = transcript.fetch()\n",
    "        return transcript_data\n",
    "    except TranscriptsDisabled:\n",
    "        raise ValueError(\"Transcripts are disabled for this video.\")\n",
    "    except NoTranscriptFound:\n",
    "        raise ValueError(\"No transcript found for this video.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred while fetching the transcript: {e}\")\n",
    "\n",
    "def format_transcript(transcript_data):\n",
    "    \"\"\"\n",
    "    Format the transcript data into a single string.\n",
    "    \"\"\"\n",
    "    formatted_text = \"\"\n",
    "    for entry in transcript_data:\n",
    "        text = entry.get('text', '').replace('\\n', ' ').strip()\n",
    "        formatted_text += text + \" \"\n",
    "    # Optionally, you can add more sophisticated formatting here\n",
    "    return formatted_text.strip()\n",
    "\n",
    "def save_transcript_to_file(text, filename):\n",
    "    \"\"\"\n",
    "    Save the transcript text to a .txt file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(text)\n",
    "        print(f\"Transcript successfully saved to '{filename}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save transcript to file: {e}\")\n",
    "\n",
    "def download_youtube_transcript(url):\n",
    "    \"\"\"\n",
    "    Main function to download the YouTube transcript.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract video ID\n",
    "        video_id = extract_video_id(url)\n",
    "        print(f\"Video ID extracted: {video_id}\")\n",
    "\n",
    "        # Get video title for filename\n",
    "        title = get_video_title(video_id)\n",
    "        safe_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", title)  # Remove illegal filename characters\n",
    "        filename = f\"{safe_title}.txt\"\n",
    "\n",
    "        # Fetch transcript\n",
    "        print(\"Fetching transcript...\")\n",
    "        transcript_data = fetch_transcript(video_id)\n",
    "\n",
    "        # Format transcript\n",
    "        print(\"Formatting transcript...\")\n",
    "        formatted_text = format_transcript(transcript_data)\n",
    "\n",
    "        # Save to file\n",
    "        save_transcript_to_file(formatted_text, filename)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=l8pRSuU81PU\"  # Replace with your YouTube URL\n",
    "download_youtube_transcript(youtube_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokenizer_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
